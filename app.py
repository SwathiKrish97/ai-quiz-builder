# -*- coding: utf-8 -*-
"""app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12OxeGfwV1QszqNHMB4ufezy-uZLZjbGh

**AI-Powered Knowledge Quiz Builder**

**0) Overview**

Build a small web app (GUI) that:

takes a topic,

- calls an LLM to generate 5 MCQs (4 options, exactly 1 correct),

- lets the user answer and submit,

- (bonus) shows the score + correct answers + explanations,

- (bonus) uses Wikipedia to improve factual accuracy,

- (bonus) persists results to a JSON file and supports review.
"""




#!/usr/bin/env python3
import os
import json
import time
import textwrap
from pathlib import Path

import requests
import gradio as gr
from dotenv import load_dotenv

# -----------------------------
# Config & model check
# -----------------------------
load_dotenv()  # reads .env if present
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
if not OPENAI_API_KEY:
    raise RuntimeError("Missing OPENAI_API_KEY. Create a .env file with your key.")

OPENAI_API_BASE = "https://api.openai.com/v1"
MODEL = "gpt-4o-mini"

# Optional diagnostics (helps reviewers)
try:
    r = requests.get(
        f"{OPENAI_API_BASE}/models",
        headers={"Authorization": f"Bearer {OPENAI_API_KEY}"},
        timeout=20,
    )
    print("Models status:", r.status_code)
    if r.status_code == 401:
        print("→ Invalid API key.")
    elif r.status_code == 429:
        print("→ Quota/credit issue on this key.")
except Exception as e:
    print("Model check failed:", e)

# -----------------------------
# Wikipedia retrieval
# -----------------------------
def wiki_summary(topic: str) -> str:
    """Return up to ~2000 chars of Wikipedia summary for grounding (optional)."""
    try:
        url = (
            "https://en.wikipedia.org/api/rest_v1/page/summary/"
            + requests.utils.quote(topic)
        )
        r = requests.get(url, headers={"accept": "application/json"}, timeout=10)
        if r.ok:
            data = r.json()
            txt = " ".join([data.get("extract", ""), data.get("description", "")]).strip()
            return txt[:2000]
    except Exception:
        pass
    return ""

# -----------------------------
# Prompt + generation
# -----------------------------
def build_prompt(topic: str, context: str = "") -> str:
    base = f"""
    You are QuizBuilder, an expert at writing clear, factually correct multiple-choice quizzes.

    GOAL: Create a quiz on the topic: "{topic}".

    OUTPUT RULES:
    - Return STRICT JSON only, matching this TypeScript type:
      type Quiz = {{
        topic: string;
        questions: {{
          question: string;
          options: string[4];
          correct_index: 0|1|2|3;
          explanation?: string;
        }}[5]
      }};
    - NO prose, NO markdown, NO code fences. JSON only.
    - Exactly 5 questions. Each has 4 distinct options and exactly one correct answer.
    - Keep questions concise and unambiguous.
    """.strip()

    if context:
        base += "\n\nKnowledge context (may help factual accuracy):\n" + context

    # Dedent to keep things neat for the model
    return textwrap.dedent(base).strip()

def generate_quiz(topic: str, use_retrieval: bool = True) -> dict:
    """Call the LLM and return validated quiz JSON."""
    ctx = wiki_summary(topic) if use_retrieval else ""
    payload = {
        "model": MODEL,
        "messages": [
            {"role": "system", "content": "You are a careful quiz generator that outputs strict JSON."},
            {"role": "user", "content": build_prompt(topic, ctx)},
        ],
        "temperature": 0.2,
        "response_format": {"type": "json_object"},  # strict JSON mode
    }
    res = requests.post(
        f"{OPENAI_API_BASE}/chat/completions",
        headers={
            "Authorization": f"Bearer {OPENAI_API_KEY}",
            "Content-Type": "application/json",
        },
        data=json.dumps(payload),
        timeout=60,
    )
    if not res.ok:
        raise RuntimeError(f"LLM error {res.status_code}: {res.text[:400]}")

    content = res.json()["choices"][0]["message"]["content"].strip().strip("`")
    data = json.loads(content)

    # --- Validation ---
    if not isinstance(data, dict):
        raise ValueError("Model did not return a JSON object.")
    qs = data.get("questions")
    if not isinstance(qs, list) or len(qs) != 5:
        raise AssertionError("Need exactly 5 questions")

    for i, q in enumerate(qs, start=1):
        if not isinstance(q, dict):
            raise AssertionError(f"Q{i} must be an object")
        question = q.get("question", "")
        options = q.get("options", [])
        ci = q.get("correct_index", None)

        if not isinstance(question, str) or not question.strip():
            raise AssertionError(f"Q{i} must have a non-empty question")
        if not isinstance(options, list) or len(options) != 4:
            raise AssertionError(f"Q{i} must have 4 options")
        if any((not isinstance(o, str) or not o.strip()) for o in options):
            raise AssertionError(f"Q{i} options must be non-empty strings")
        if not isinstance(ci, int) or not (0 <= ci <= 3):
            raise AssertionError(f"Q{i} correct_index out of range")
        if len(set(o.strip() for o in options)) != 4:
            raise AssertionError(f"Q{i} options must be distinct")

    data.setdefault("topic", topic)
    return data

# -----------------------------
# Persistence
# -----------------------------
RESULTS_FILE = str((Path.cwd() / "results.json").resolve())
print("results.json will be written to:", RESULTS_FILE)

def save_results(topic, score, answers, quiz):
    normalized_qs = []
    for q, a in zip(quiz["questions"], answers):
        opts = q["options"]
        correct_idx = q["correct_index"]
        correct_text = opts[correct_idx]

        user_index = None
        user_text = None

        if a is None:
            user_index = None
            user_text = None
        elif isinstance(a, int):
            user_index = a if 0 <= a < len(opts) else None
            user_text = opts[user_index] if user_index is not None else None
        else:
            a_str = str(a)
            user_text = a_str
            user_index = opts.index(a_str) if a_str in opts else None

        normalized_qs.append(
            {
                "question": q["question"],
                "options": opts,
                "correct_index": correct_idx,
                "correct_text": correct_text,
                "user_index": user_index,
                "user_text": user_text,
                "explanation": q.get("explanation", ""),
            }
        )

    record = {
        "timestamp": time.strftime("%Y-%m-%dT%H:%M:%S"),
        "topic": topic,
        "score": score,
        "questions": normalized_qs,
    }

    try:
        existing = json.loads(Path(RESULTS_FILE).read_text()) if Path(RESULTS_FILE).exists() else []
    except Exception:
        existing = []

    existing.append(record)
    Path(RESULTS_FILE).write_text(json.dumps(existing, indent=2))
    print("✅ Saved to", RESULTS_FILE)

def load_results():
    try:
        if Path(RESULTS_FILE).exists():
            return json.loads(Path(RESULTS_FILE).read_text())
    except Exception:
        pass
    return []

def show_history():
    rows = load_results()
    if not rows:
        return "No past quizzes yet."
    last = rows[-5:]
    lines = []
    for r in last:
        score_str = f"{r.get('score', 0)}/5"
        lines.append(f"- **{r.get('timestamp','')}** — Topic: **{r.get('topic','')}**, Score: **{score_str}**")
    return "\n".join(lines)

# -----------------------------
# Gradio UI
# -----------------------------
with gr.Blocks(title="AI Quiz Builder") as demo:
    gr.Markdown("## AI-Powered Knowledge Quiz Builder")

    topic = gr.Textbox(label="Topic", placeholder="e.g., Photosynthesis")
    use_retrieval = gr.Checkbox(value=True, label="Use Wikipedia grounding")
    generate_btn = gr.Button("Generate Quiz")

    radios = [gr.Radio(choices=[], label=f"Q{i+1}", visible=False) for i in range(5)]

    submit_btn = gr.Button("Submit Answers")
    result = gr.Markdown()

    review_btn = gr.Button("Review Past Results")
    history_md = gr.Markdown()

    state_quiz = gr.State(None)

    def on_generate(t, retrieve):
        try:
            quiz = generate_quiz(t, use_retrieval=retrieve)
            radio_updates = [
                gr.update(
                    choices=[f"{chr(65+j)}. {opt}" for j, opt in enumerate(q["options"])],
                    value=None,
                    visible=True,
                    label=f"Q{i+1}. {q['question']}",
                )
                for i, q in enumerate(quiz["questions"])
            ]
            return [quiz, *radio_updates]
        except Exception as e:
            # Hide radios on failure
            radio_updates = [gr.update(choices=[], value=None, visible=False) for _ in range(5)]
            return [None, *radio_updates]

    def on_submit(topic_text, quiz_state, *answers):
        if not quiz_state:
            return "Generate a quiz first."

        # Strip "A. ", "B. " prefix before lookup
        cleaned_answers = [a.split(". ", 1)[1] if isinstance(a, str) and ". " in a else a for a in answers]

        score = 0
        lines = []
        for i, (q, ans) in enumerate(zip(quiz_state["questions"], cleaned_answers), start=1):
            sel = q["options"].index(ans) if isinstance(ans, str) and ans in q["options"] else None
            ci = q["correct_index"]
            ok = (sel == ci)
            score += 1 if ok else 0
            lines.append(
                f"**Q{i}. {q['question']}**\n"
                f"- Your answer: {ans if ans else '—'}\n"
                f"- Correct: {q['options'][ci]}\n"
                + (f"- Why: {q.get('explanation','')}\n" if q.get('explanation') else "")
            )

        try:
            save_results(topic_text, score, cleaned_answers, quiz_state)
        except Exception as e:
            lines.append(f"\n*Note:* Could not save results ({e}).")

        return f"### Score: **{score}/5**\n\n" + "\n".join(lines)

    generate_btn.click(fn=on_generate, inputs=[topic, use_retrieval], outputs=[state_quiz, *radios])
    submit_btn.click(fn=on_submit, inputs=[topic, state_quiz, *radios], outputs=[result])
    review_btn.click(fn=show_history, inputs=[], outputs=history_md)

if __name__ == "__main__":
    # For local terminal runs; set share=True if you want a public URL
    demo.launch()
